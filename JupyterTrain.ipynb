{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\saibi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Create YOLOv3 model with 9 anchors and 1 classes.\n",
      "Load weights model_data/yolo_weights.h5.\n",
      "Freeze the first 249 layers of total 252 layers.\n",
      "Train on 89 samples, val on 9 samples, with batch size 32.\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 73s 37s/step - loss: 7362.8181 - val_loss: nan\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 61s 31s/step - loss: 7334.2390 - val_loss: nan\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 7300.9824 - val_loss: nan\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\saibi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\callbacks.py:436: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 61s 31s/step - loss: 7274.3052 - val_loss: nan\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 7241.5693 - val_loss: nan\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 61s 31s/step - loss: 7211.6152 - val_loss: nan\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 7180.6218 - val_loss: nan\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 7152.8838 - val_loss: nan\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 7120.9358 - val_loss: nan\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 61s 31s/step - loss: 7090.7925 - val_loss: nan\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 7063.1653 - val_loss: nan\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 61s 31s/step - loss: 7035.0491 - val_loss: nan\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 61s 31s/step - loss: 7004.5784 - val_loss: nan\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 61s 31s/step - loss: 6976.9941 - val_loss: nan\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 63s 31s/step - loss: 6949.0266 - val_loss: nan\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 63s 31s/step - loss: 6918.9312 - val_loss: nan\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6893.1489 - val_loss: nan\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 63s 31s/step - loss: 6863.0471 - val_loss: nan\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 63s 31s/step - loss: 6834.5059 - val_loss: nan\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 63s 31s/step - loss: 6805.6733 - val_loss: nan\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6778.8596 - val_loss: nan\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6750.9143 - val_loss: nan\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6724.2698 - val_loss: nan\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 63s 31s/step - loss: 6694.9299 - val_loss: nan\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 63s 31s/step - loss: 6667.4182 - val_loss: nan\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6639.0017 - val_loss: nan\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6613.8960 - val_loss: nan\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6589.5981 - val_loss: nan\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6560.1265 - val_loss: nan\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6535.6238 - val_loss: nan\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6510.8369 - val_loss: nan\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 63s 31s/step - loss: 6481.4143 - val_loss: nan\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 63s 31s/step - loss: 6455.4448 - val_loss: nan\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 63s 31s/step - loss: 6429.5181 - val_loss: nan\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6403.6509 - val_loss: nan\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 63s 31s/step - loss: 6377.3979 - val_loss: nan\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6351.4844 - val_loss: nan\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 63s 31s/step - loss: 6326.1575 - val_loss: nan\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6301.0579 - val_loss: nan\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6276.1553 - val_loss: nan\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6250.9941 - val_loss: nan\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 63s 31s/step - loss: 6227.2900 - val_loss: nan\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6200.6519 - val_loss: nan\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6177.9019 - val_loss: nan\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6152.9587 - val_loss: nan\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6129.4937 - val_loss: nan\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 63s 31s/step - loss: 6103.5508 - val_loss: nan\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6080.4158 - val_loss: nan\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6056.1953 - val_loss: nan\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 63s 31s/step - loss: 6031.8508 - val_loss: nan\n",
      "Unfreeze all of the layers.\n",
      "Train on 89 samples, val on 9 samples, with batch size 32.\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 211s 105s/step - loss: 6010.0737 - val_loss: 5972.0391\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 187s 94s/step - loss: 5988.0425 - val_loss: 5934.9004\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 187s 93s/step - loss: 5965.3728 - val_loss: 5902.4180\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 187s 94s/step - loss: 5944.4507 - val_loss: 5869.3682\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 193s 97s/step - loss: 5922.8828 - val_loss: 5836.0244\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 194s 97s/step - loss: 5902.6050 - val_loss: 5804.4834\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 193s 96s/step - loss: 5878.1858 - val_loss: 5768.6763\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 187s 93s/step - loss: 5855.9133 - val_loss: 5736.4756\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 187s 94s/step - loss: 5833.0798 - val_loss: 5705.5171\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 187s 94s/step - loss: 5812.5464 - val_loss: 5669.3589\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 186s 93s/step - loss: 5789.4214 - val_loss: 5633.3193\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 187s 93s/step - loss: 5766.2981 - val_loss: 5596.7759\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 187s 94s/step - loss: 5745.5447 - val_loss: 5561.9736\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 187s 94s/step - loss: 5722.2219 - val_loss: 5539.6299\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 187s 93s/step - loss: 5701.7598 - val_loss: 5492.2397\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 186s 93s/step - loss: 5677.2407 - val_loss: 5461.0513\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 186s 93s/step - loss: 5656.3694 - val_loss: 5425.9697\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 187s 93s/step - loss: 5634.4263 - val_loss: 5417.6870\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 187s 94s/step - loss: 5613.1621 - val_loss: 5378.7993\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 188s 94s/step - loss: 5593.6663 - val_loss: 5360.3682\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 186s 93s/step - loss: 5571.3059 - val_loss: 5357.3174\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 186s 93s/step - loss: 5550.9180 - val_loss: 5324.1899\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 188s 94s/step - loss: 5529.6042 - val_loss: 5322.8228\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 187s 93s/step - loss: 5509.2324 - val_loss: 5311.2603\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 186s 93s/step - loss: 5489.7773 - val_loss: 5290.3135\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 187s 94s/step - loss: 5467.5239 - val_loss: 5270.5542\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 187s 93s/step - loss: 5448.5220 - val_loss: 5224.4941\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 189s 94s/step - loss: 5426.2542 - val_loss: 5227.6577\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 186s 93s/step - loss: 5405.8125 - val_loss: 5198.8184\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 187s 93s/step - loss: 5384.3123 - val_loss: 5171.8003\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 187s 93s/step - loss: 5364.4922 - val_loss: 5152.5801\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 186s 93s/step - loss: 5341.9082 - val_loss: 5114.2651\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 186s 93s/step - loss: 5320.2827 - val_loss: 5066.0229\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 188s 94s/step - loss: 5299.2773 - val_loss: 5016.5186\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 187s 93s/step - loss: 5277.6438 - val_loss: 4972.6211\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 189s 94s/step - loss: 5254.4558 - val_loss: 4922.5547\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 192s 96s/step - loss: 5233.4980 - val_loss: 4891.3530\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 186s 93s/step - loss: 5214.1360 - val_loss: 4859.8608\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 187s 93s/step - loss: 5191.9526 - val_loss: 4814.9160\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 187s 94s/step - loss: 5171.2961 - val_loss: 4793.7476\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 188s 94s/step - loss: 5150.2976 - val_loss: 4756.4062\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 186s 93s/step - loss: 5131.1829 - val_loss: 4736.0879\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 186s 93s/step - loss: 5109.9216 - val_loss: 4735.3237\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 187s 94s/step - loss: 5090.0430 - val_loss: 4727.4868\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 187s 94s/step - loss: 5070.8669 - val_loss: 4715.0337\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 187s 93s/step - loss: 5049.2620 - val_loss: 4715.4902\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 188s 94s/step - loss: 5029.9082 - val_loss: 4705.7397\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 187s 94s/step - loss: 5010.8169 - val_loss: 4699.5171\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 187s 93s/step - loss: 4991.6553 - val_loss: 4687.8838\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 187s 93s/step - loss: 4969.8286 - val_loss: 4687.9517\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Retrain the YOLO model for your own dataset.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "from yolo3.model import preprocess_true_boxes, yolo_body, tiny_yolo_body, yolo_loss\n",
    "from yolo3.utils import get_random_data\n",
    "\n",
    "\n",
    "def _main():\n",
    "    annotation_path = 'labelbox.txt'#'train.txt'\n",
    "    log_dir = 'logs/000/'\n",
    "    classes_path = 'model_data/highway_classes.txt'\n",
    "    anchors_path = 'model_data/yolo_anchors.txt'\n",
    "    class_names = get_classes(classes_path)\n",
    "    num_classes = len(class_names)\n",
    "    anchors = get_anchors(anchors_path)\n",
    "\n",
    "    input_shape = (416,416) # multiple of 32, hw\n",
    "\n",
    "    is_tiny_version = len(anchors)==6 # default setting\n",
    "    if is_tiny_version:\n",
    "        model = create_tiny_model(input_shape, anchors, num_classes,\n",
    "            freeze_body=2, weights_path='model_data/tiny_yolo_weights.h5')\n",
    "    else:\n",
    "        model = create_model(input_shape, anchors, num_classes,\n",
    "            freeze_body=2, weights_path='model_data/yolo_weights.h5') # make sure you know what you freeze\n",
    "\n",
    "    logging = TensorBoard(log_dir=log_dir)\n",
    "    checkpoint = ModelCheckpoint(log_dir + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',\n",
    "        monitor='val_loss', save_weights_only=True, save_best_only=True, period=3)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)\n",
    "\n",
    "    val_split = 0.1\n",
    "    with open(annotation_path) as f:\n",
    "        lines = f.readlines()\n",
    "    np.random.seed(10101)\n",
    "    np.random.shuffle(lines)\n",
    "    np.random.seed(None)\n",
    "    num_val = int(len(lines)*val_split)\n",
    "    num_train = len(lines) - num_val\n",
    "\n",
    "    # Train with frozen layers first, to get a stable loss.\n",
    "    # Adjust num epochs to your dataset. This step is enough to obtain a not bad model.\n",
    "    if True:\n",
    "        model.compile(optimizer=Adam(lr=1e-3), loss={\n",
    "            # use custom yolo_loss Lambda layer.\n",
    "            'yolo_loss': lambda y_true, y_pred: y_pred})\n",
    "\n",
    "        batch_size = 32\n",
    "        print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
    "        model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
    "                steps_per_epoch=max(1, num_train//batch_size),\n",
    "                validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
    "                validation_steps=max(1, num_val//batch_size),\n",
    "                epochs=50,\n",
    "                initial_epoch=0,\n",
    "                callbacks=[logging, checkpoint])\n",
    "        model.save_weights(log_dir + 'trained_weights_stage_1.h5')\n",
    "\n",
    "    # Unfreeze and continue training, to fine-tune.\n",
    "    # Train longer if the result is not good.\n",
    "    if True:\n",
    "        for i in range(len(model.layers)):\n",
    "            model.layers[i].trainable = True\n",
    "        model.compile(optimizer=Adam(lr=1e-4), loss={'yolo_loss': lambda y_true, y_pred: y_pred}) # recompile to apply the change\n",
    "        print('Unfreeze all of the layers.')\n",
    "\n",
    "        batch_size = 32 # note that more GPU memory is required after unfreezing the body\n",
    "        print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
    "        model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
    "            steps_per_epoch=max(1, num_train//batch_size),\n",
    "            validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
    "            validation_steps=max(1, num_val//batch_size),\n",
    "            epochs=100,\n",
    "            initial_epoch=50,\n",
    "            callbacks=[logging, checkpoint, reduce_lr, early_stopping])\n",
    "        model.save_weights(log_dir + 'trained_weights_final.h5')\n",
    "\n",
    "    # Further training if needed.\n",
    "\n",
    "\n",
    "def get_classes(classes_path):\n",
    "    '''loads the classes'''\n",
    "    with open(classes_path) as f:\n",
    "        class_names = f.readlines()\n",
    "    class_names = [c.strip() for c in class_names]\n",
    "    return class_names\n",
    "\n",
    "def get_anchors(anchors_path):\n",
    "    '''loads the anchors from a file'''\n",
    "    with open(anchors_path) as f:\n",
    "        anchors = f.readline()\n",
    "    anchors = [float(x) for x in anchors.split(',')]\n",
    "    return np.array(anchors).reshape(-1, 2)\n",
    "\n",
    "\n",
    "def create_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=2,\n",
    "            weights_path='model_data/yolo_weights.h5'):\n",
    "    '''create the training model'''\n",
    "    K.clear_session() # get a new session\n",
    "    image_input = Input(shape=(None, None, 3))\n",
    "    h, w = input_shape\n",
    "    num_anchors = len(anchors)\n",
    "\n",
    "    y_true = [Input(shape=(h//{0:32, 1:16, 2:8}[l], w//{0:32, 1:16, 2:8}[l], \\\n",
    "        num_anchors//3, num_classes+5)) for l in range(3)]\n",
    "\n",
    "    model_body = yolo_body(image_input, num_anchors//3, num_classes)\n",
    "    print('Create YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
    "\n",
    "    if load_pretrained:\n",
    "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
    "        print('Load weights {}.'.format(weights_path))\n",
    "        if freeze_body in [1, 2]:\n",
    "            # Freeze darknet53 body or freeze all but 3 output layers.\n",
    "            num = (185, len(model_body.layers)-3)[freeze_body-1]\n",
    "            for i in range(num): model_body.layers[i].trainable = False\n",
    "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
    "\n",
    "    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
    "        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.5})(\n",
    "        [*model_body.output, *y_true])\n",
    "    model = Model([model_body.input, *y_true], model_loss)\n",
    "\n",
    "    return model\n",
    "\n",
    "def create_tiny_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=2,\n",
    "            weights_path='model_data/tiny_yolo_weights.h5'):\n",
    "    '''create the training model, for Tiny YOLOv3'''\n",
    "    K.clear_session() # get a new session\n",
    "    image_input = Input(shape=(None, None, 3))\n",
    "    h, w = input_shape\n",
    "    num_anchors = len(anchors)\n",
    "\n",
    "    y_true = [Input(shape=(h//{0:32, 1:16}[l], w//{0:32, 1:16}[l], \\\n",
    "        num_anchors//2, num_classes+5)) for l in range(2)]\n",
    "\n",
    "    model_body = tiny_yolo_body(image_input, num_anchors//2, num_classes)\n",
    "    print('Create Tiny YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
    "\n",
    "    if load_pretrained:\n",
    "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
    "        print('Load weights {}.'.format(weights_path))\n",
    "        if freeze_body in [1, 2]:\n",
    "            # Freeze the darknet body or freeze all but 2 output layers.\n",
    "            num = (20, len(model_body.layers)-2)[freeze_body-1]\n",
    "            for i in range(num): model_body.layers[i].trainable = False\n",
    "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
    "\n",
    "    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
    "        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.7})(\n",
    "        [*model_body.output, *y_true])\n",
    "    model = Model([model_body.input, *y_true], model_loss)\n",
    "\n",
    "    return model\n",
    "\n",
    "def data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
    "    '''data generator for fit_generator'''\n",
    "    n = len(annotation_lines)\n",
    "    i = 0\n",
    "    while True:\n",
    "        image_data = []\n",
    "        box_data = []\n",
    "        for b in range(batch_size):\n",
    "            if i==0:\n",
    "                np.random.shuffle(annotation_lines)\n",
    "            image, box = get_random_data(annotation_lines[i], input_shape, random=True)\n",
    "            image_data.append(image)\n",
    "            box_data.append(box)\n",
    "            i = (i+1) % n\n",
    "        image_data = np.array(image_data)\n",
    "        box_data = np.array(box_data)\n",
    "        y_true = preprocess_true_boxes(box_data, input_shape, anchors, num_classes)\n",
    "        yield [image_data, *y_true], np.zeros(batch_size)\n",
    "\n",
    "def data_generator_wrapper(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
    "    n = len(annotation_lines)\n",
    "    if n==0 or batch_size<=0: return None\n",
    "    return data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    _main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
