{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\saibi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Create YOLOv3 model with 9 anchors and 1 classes.\n",
      "Load weights model_data/yolo_weights.h5.\n",
      "Freeze the first 249 layers of total 252 layers.\n",
      "Train on 89 samples, val on 9 samples, with batch size 32.\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 74s 37s/step - loss: 7363.8445 - val_loss: nan\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 7331.5276 - val_loss: nan\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 7301.7144 - val_loss: nan\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\saibi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\callbacks.py:436: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 62s 31s/step - loss: 7270.4094 - val_loss: nan\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 7240.5632 - val_loss: nan\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 7212.9438 - val_loss: nan\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 63s 31s/step - loss: 7181.8215 - val_loss: nan\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 63s 31s/step - loss: 7152.0332 - val_loss: nan\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 7122.7959 - val_loss: nan\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 7092.3125 - val_loss: nan\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 7062.3804 - val_loss: nan\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 7033.5500 - val_loss: nan\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 7007.2705 - val_loss: nan\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6977.3416 - val_loss: nan\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6947.9949 - val_loss: nan\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6918.7285 - val_loss: nan\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6891.0945 - val_loss: nan\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6862.6780 - val_loss: nan\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 63s 31s/step - loss: 6835.9829 - val_loss: nan\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6807.5906 - val_loss: nan\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6776.3540 - val_loss: nan\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6748.6614 - val_loss: nan\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6721.5576 - val_loss: nan\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6694.3274 - val_loss: nan\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6668.7764 - val_loss: nan\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6641.3628 - val_loss: nan\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6613.6572 - val_loss: nan\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6587.5759 - val_loss: nan\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6560.8113 - val_loss: nan\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6535.9714 - val_loss: nan\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6507.2896 - val_loss: nan\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6482.3335 - val_loss: nan\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6457.3352 - val_loss: nan\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6429.6279 - val_loss: nan\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 63s 31s/step - loss: 6404.8389 - val_loss: nan\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6378.5371 - val_loss: nan\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6352.3647 - val_loss: nan\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6327.4888 - val_loss: nan\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6301.7214 - val_loss: nan\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6276.0774 - val_loss: nan\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6251.4258 - val_loss: nan\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6225.1643 - val_loss: nan\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6204.1348 - val_loss: nan\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6177.9578 - val_loss: nan\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6150.9670 - val_loss: nan\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6129.0449 - val_loss: nan\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6103.7979 - val_loss: nan\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6078.6265 - val_loss: nan\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6056.6658 - val_loss: nan\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 62s 31s/step - loss: 6032.6543 - val_loss: nan\n",
      "Unfreeze all of the layers.\n",
      "Train on 89 samples, val on 9 samples, with batch size 32.\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 208s 104s/step - loss: 6009.8071 - val_loss: 5971.3262\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 194s 97s/step - loss: 5987.3733 - val_loss: 5935.8101\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 186s 93s/step - loss: 5962.8945 - val_loss: 5906.1421\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 191s 96s/step - loss: 5943.7993 - val_loss: 5873.9736\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 186s 93s/step - loss: 5925.2275 - val_loss: 5837.3237\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 190s 95s/step - loss: 5902.1877 - val_loss: 5799.3687\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 186s 93s/step - loss: 5879.1316 - val_loss: 5769.0225\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 186s 93s/step - loss: 5856.2839 - val_loss: 5736.0640\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 186s 93s/step - loss: 5832.7769 - val_loss: 5698.2432\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 187s 94s/step - loss: 5812.9080 - val_loss: 5661.0796\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 186s 93s/step - loss: 5787.5549 - val_loss: 5626.9541\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 186s 93s/step - loss: 5766.7727 - val_loss: 5594.2378\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 186s 93s/step - loss: 5744.8396 - val_loss: 5562.0059\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 187s 93s/step - loss: 5723.6431 - val_loss: 5530.0889\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 186s 93s/step - loss: 5699.6995 - val_loss: 5491.3037\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 186s 93s/step - loss: 5676.0261 - val_loss: 5456.4263\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 186s 93s/step - loss: 5654.8354 - val_loss: 5434.1909\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 186s 93s/step - loss: 5633.4819 - val_loss: 5397.4868\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 186s 93s/step - loss: 5613.5728 - val_loss: 5373.1362\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 186s 93s/step - loss: 5593.6836 - val_loss: 5356.8911\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 186s 93s/step - loss: 5572.1858 - val_loss: 5350.0352\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 186s 93s/step - loss: 5550.9189 - val_loss: 5336.3413\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 186s 93s/step - loss: 5530.6875 - val_loss: 5323.7920\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 186s 93s/step - loss: 5506.9045 - val_loss: 5301.0552\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 186s 93s/step - loss: 5489.8167 - val_loss: 5277.3838\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 187s 93s/step - loss: 5466.3596 - val_loss: 5268.7754\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 187s 93s/step - loss: 5449.0493 - val_loss: 5234.2334\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 186s 93s/step - loss: 5424.9976 - val_loss: 5223.4453\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 186s 93s/step - loss: 5404.3083 - val_loss: 5213.6133\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 186s 93s/step - loss: 5385.9478 - val_loss: 5191.9517\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 186s 93s/step - loss: 5360.9946 - val_loss: 5172.2046\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 186s 93s/step - loss: 5340.4067 - val_loss: 5116.1348\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 186s 93s/step - loss: 5318.8252 - val_loss: 5057.3242\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 186s 93s/step - loss: 5298.3945 - val_loss: 5021.1548\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 187s 94s/step - loss: 5276.4360 - val_loss: 4971.6631\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 187s 93s/step - loss: 5254.2424 - val_loss: 4937.5508\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 186s 93s/step - loss: 5231.5115 - val_loss: 4904.4160\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 186s 93s/step - loss: 5211.2295 - val_loss: 4857.0469\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 186s 93s/step - loss: 5189.5454 - val_loss: 4829.2617\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 187s 93s/step - loss: 5168.9670 - val_loss: 4803.0190\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 186s 93s/step - loss: 5148.8923 - val_loss: 4785.6714\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 186s 93s/step - loss: 5127.3547 - val_loss: 4782.7061\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 186s 93s/step - loss: 5109.3621 - val_loss: 4777.5073\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 186s 93s/step - loss: 5089.3479 - val_loss: 4758.9224\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 186s 93s/step - loss: 5069.4480 - val_loss: 4756.0005\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 186s 93s/step - loss: 5049.1787 - val_loss: 4748.3574\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 186s 93s/step - loss: 5027.1038 - val_loss: 4740.1772\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 186s 93s/step - loss: 5008.6208 - val_loss: 4732.2729\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 186s 93s/step - loss: 4991.1279 - val_loss: 4718.5176\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 186s 93s/step - loss: 4968.4055 - val_loss: 4706.7163\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Retrain the YOLO model for your own dataset.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "from yolo3.model import preprocess_true_boxes, yolo_body, tiny_yolo_body, yolo_loss\n",
    "from yolo3.utils import get_random_data\n",
    "\n",
    "\n",
    "def _main():\n",
    "    annotation_path = 'labelbox.txt'#'train.txt'\n",
    "    log_dir = 'logs/000/'\n",
    "    classes_path = 'model_data/highway_classes.txt'\n",
    "    anchors_path = 'model_data/yolo_anchors.txt'\n",
    "    class_names = get_classes(classes_path)\n",
    "    num_classes = len(class_names)\n",
    "    anchors = get_anchors(anchors_path)\n",
    "\n",
    "    input_shape = (416,416) # multiple of 32, hw\n",
    "\n",
    "    is_tiny_version = len(anchors)==6 # default setting\n",
    "    if is_tiny_version:\n",
    "        model = create_tiny_model(input_shape, anchors, num_classes,\n",
    "            freeze_body=2, weights_path='model_data/tiny_yolo_weights.h5')\n",
    "    else:\n",
    "        model = create_model(input_shape, anchors, num_classes,\n",
    "            freeze_body=2, weights_path='model_data/yolo_weights.h5') # make sure you know what you freeze\n",
    "\n",
    "    logging = TensorBoard(log_dir=log_dir)\n",
    "    checkpoint = ModelCheckpoint(log_dir + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',\n",
    "        monitor='val_loss', save_weights_only=True, save_best_only=True, period=3)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)\n",
    "\n",
    "    val_split = 0.1\n",
    "    with open(annotation_path) as f:\n",
    "        lines = f.readlines()\n",
    "    np.random.seed(10101)\n",
    "    np.random.shuffle(lines)\n",
    "    np.random.seed(None)\n",
    "    num_val = int(len(lines)*val_split)\n",
    "    num_train = len(lines) - num_val\n",
    "\n",
    "    # Train with frozen layers first, to get a stable loss.\n",
    "    # Adjust num epochs to your dataset. This step is enough to obtain a not bad model.\n",
    "    if True:\n",
    "        model.compile(optimizer=Adam(lr=1e-3), loss={\n",
    "            # use custom yolo_loss Lambda layer.\n",
    "            'yolo_loss': lambda y_true, y_pred: y_pred})\n",
    "\n",
    "        batch_size = 32\n",
    "        print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
    "        model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
    "                steps_per_epoch=max(1, num_train//batch_size),\n",
    "                validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
    "                validation_steps=max(1, num_val//batch_size),\n",
    "                epochs=50,\n",
    "                initial_epoch=0,\n",
    "                callbacks=[logging, checkpoint])\n",
    "        model.save_weights(log_dir + 'trained_weights_stage_1.h5')\n",
    "\n",
    "    # Unfreeze and continue training, to fine-tune.\n",
    "    # Train longer if the result is not good.\n",
    "    if True:\n",
    "        for i in range(len(model.layers)):\n",
    "            model.layers[i].trainable = True\n",
    "        model.compile(optimizer=Adam(lr=1e-4), loss={'yolo_loss': lambda y_true, y_pred: y_pred}) # recompile to apply the change\n",
    "        print('Unfreeze all of the layers.')\n",
    "\n",
    "        batch_size = 32 # note that more GPU memory is required after unfreezing the body\n",
    "        print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
    "        model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
    "            steps_per_epoch=max(1, num_train//batch_size),\n",
    "            validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
    "            validation_steps=max(1, num_val//batch_size),\n",
    "            epochs=100,\n",
    "            initial_epoch=50,\n",
    "            callbacks=[logging, checkpoint, reduce_lr, early_stopping])\n",
    "        model.save_weights(log_dir + 'trained_weights_final.h5')\n",
    "\n",
    "    # Further training if needed.\n",
    "\n",
    "\n",
    "def get_classes(classes_path):\n",
    "    '''loads the classes'''\n",
    "    with open(classes_path) as f:\n",
    "        class_names = f.readlines()\n",
    "    class_names = [c.strip() for c in class_names]\n",
    "    return class_names\n",
    "\n",
    "def get_anchors(anchors_path):\n",
    "    '''loads the anchors from a file'''\n",
    "    with open(anchors_path) as f:\n",
    "        anchors = f.readline()\n",
    "    anchors = [float(x) for x in anchors.split(',')]\n",
    "    return np.array(anchors).reshape(-1, 2)\n",
    "\n",
    "\n",
    "def create_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=2,\n",
    "            weights_path='model_data/yolo_weights.h5'):\n",
    "    '''create the training model'''\n",
    "    K.clear_session() # get a new session\n",
    "    image_input = Input(shape=(None, None, 3))\n",
    "    h, w = input_shape\n",
    "    num_anchors = len(anchors)\n",
    "\n",
    "    y_true = [Input(shape=(h//{0:32, 1:16, 2:8}[l], w//{0:32, 1:16, 2:8}[l], \\\n",
    "        num_anchors//3, num_classes+5)) for l in range(3)]\n",
    "\n",
    "    model_body = yolo_body(image_input, num_anchors//3, num_classes)\n",
    "    print('Create YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
    "\n",
    "    if load_pretrained:\n",
    "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
    "        print('Load weights {}.'.format(weights_path))\n",
    "        if freeze_body in [1, 2]:\n",
    "            # Freeze darknet53 body or freeze all but 3 output layers.\n",
    "            num = (185, len(model_body.layers)-3)[freeze_body-1]\n",
    "            for i in range(num): model_body.layers[i].trainable = False\n",
    "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
    "\n",
    "    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
    "        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.5})(\n",
    "        [*model_body.output, *y_true])\n",
    "    model = Model([model_body.input, *y_true], model_loss)\n",
    "\n",
    "    return model\n",
    "\n",
    "def create_tiny_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=2,\n",
    "            weights_path='model_data/tiny_yolo_weights.h5'):\n",
    "    '''create the training model, for Tiny YOLOv3'''\n",
    "    K.clear_session() # get a new session\n",
    "    image_input = Input(shape=(None, None, 3))\n",
    "    h, w = input_shape\n",
    "    num_anchors = len(anchors)\n",
    "\n",
    "    y_true = [Input(shape=(h//{0:32, 1:16}[l], w//{0:32, 1:16}[l], \\\n",
    "        num_anchors//2, num_classes+5)) for l in range(2)]\n",
    "\n",
    "    model_body = tiny_yolo_body(image_input, num_anchors//2, num_classes)\n",
    "    print('Create Tiny YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
    "\n",
    "    if load_pretrained:\n",
    "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
    "        print('Load weights {}.'.format(weights_path))\n",
    "        if freeze_body in [1, 2]:\n",
    "            # Freeze the darknet body or freeze all but 2 output layers.\n",
    "            num = (20, len(model_body.layers)-2)[freeze_body-1]\n",
    "            for i in range(num): model_body.layers[i].trainable = False\n",
    "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
    "\n",
    "    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
    "        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.7})(\n",
    "        [*model_body.output, *y_true])\n",
    "    model = Model([model_body.input, *y_true], model_loss)\n",
    "\n",
    "    return model\n",
    "\n",
    "def data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
    "    '''data generator for fit_generator'''\n",
    "    n = len(annotation_lines)\n",
    "    i = 0\n",
    "    while True:\n",
    "        image_data = []\n",
    "        box_data = []\n",
    "        for b in range(batch_size):\n",
    "            if i==0:\n",
    "                np.random.shuffle(annotation_lines)\n",
    "            image, box = get_random_data(annotation_lines[i], input_shape, random=True)\n",
    "            image_data.append(image)\n",
    "            box_data.append(box)\n",
    "            i = (i+1) % n\n",
    "        image_data = np.array(image_data)\n",
    "        box_data = np.array(box_data)\n",
    "        y_true = preprocess_true_boxes(box_data, input_shape, anchors, num_classes)\n",
    "        yield [image_data, *y_true], np.zeros(batch_size)\n",
    "\n",
    "def data_generator_wrapper(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
    "    n = len(annotation_lines)\n",
    "    if n==0 or batch_size<=0: return None\n",
    "    return data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    _main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
